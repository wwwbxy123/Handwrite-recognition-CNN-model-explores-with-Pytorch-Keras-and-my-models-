{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part2 experiment with my dataset.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "wRZk9J60MI2U",
        "hqhqzm47JWfC",
        "IkM8HvalLrqI",
        "Loj16xeRLw97",
        "eY9UR5pCL22B"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wwwbxy123/Handwrite-recognition-CNN-model-explores-with-Pytorch-Keras-and-my-models-/blob/master/Part2_experiment_with_my_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "HFaJAIhfMCVv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Part 2 Experiment with my dataset"
      ]
    },
    {
      "metadata": {
        "id": "wRZk9J60MI2U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Prepare the model and load my dataset"
      ]
    },
    {
      "metadata": {
        "id": "zhx0lFViFm2k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#install torch in google colab\n",
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nfiM3AQXFqkO",
        "colab_type": "code",
        "outputId": "55f4c7ff-053e-4e78-d840-a4831e8f11dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.4.1\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hgAEBppGFtub",
        "colab_type": "code",
        "outputId": "900053d1-9417-4337-d3c6-9b46a97c8f96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "#initialization\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper parameters\n",
        "num_epochs = 5\n",
        "num_classes = 10\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "# MNIST dataset\n",
        "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=None)\n",
        "len(mnist_trainset)\n",
        "print(mnist_trainset)\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data/',\n",
        "                                           train=True, \n",
        "                                           transform=transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data/',\n",
        "                                          train=False, \n",
        "                                          transform=transforms.ToTensor())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset MNIST\n",
            "    Number of datapoints: 60000\n",
            "    Split: train\n",
            "    Root Location: ./data\n",
            "    Transforms (if any): None\n",
            "    Target Transforms (if any): None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FgbhYfoqF2GN",
        "colab_type": "code",
        "outputId": "aded9aac-4628-4649-b9e1-92e03a06aadb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "cell_type": "code",
      "source": [
        "# Mounte files to gdrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wH3CZkCfF4zm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# loade test myDateSet\n",
        "\n",
        "import pandas as pd\n",
        "from matplotlib.pyplot import imshow\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torchvision import transforms\n",
        "\n",
        "class SimpleDataset(Dataset):\n",
        "    def __init__(self, data_path, csv_name, transform = None ):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data_path (string): path to the folder where images and csv files are located\n",
        "            csv_name (string): name of the csv lablel file\n",
        "            transform: pytorch transforms for transforms and tensor conversion\n",
        "        \"\"\"\n",
        "        # Set path\n",
        "        self.data_path = data_path\n",
        "        # Transforms\n",
        "        self.transform = transform\n",
        "        # Read the csv file\n",
        "        self.data_info = pd.read_csv(data_path + csv_name, header=None)\n",
        "        # First column contains the image paths\n",
        "        self.image_arr = np.asarray(self.data_info.iloc[:, 0])\n",
        "        # Second column is the labels\n",
        "        self.label_arr = np.asarray(self.data_info.iloc[:, 1])\n",
        "        # Calculate len\n",
        "        self.data_len = len(self.data_info.index)\n",
        "        \n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Get image name from the pandas df\n",
        "        single_image_name = self.image_arr[index]\n",
        "        # Open image\n",
        "        img_as_img = Image.open(self.data_path + single_image_name)\n",
        "        if self.transform is not None:\n",
        "              img_as_img = self.transform(img_as_img)\n",
        "\n",
        "        # Get label(class) of the image based on the cropped pandas column\n",
        "        single_image_label = self.label_arr[index]\n",
        "        #convert to tensor to be consistent with MNIST dataset\n",
        "        single_image_label = torch.LongTensor( [ single_image_label ] )[0]\n",
        "        return (img_as_img, single_image_label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data_len\n",
        "\n",
        "#mydata = SimpleDataset( \"gdrive/My Drive/myDataSet/\", \"label.csv\")\n",
        "mydataT = SimpleDataset( \"gdrive/My Drive/myDataSet/\", \"label.csv\", transform=transforms.ToTensor())\n",
        "\n",
        "#testc = mydataT[1]\n",
        "#testT = testc[0]\n",
        "#imgt = Image.fromarray((testT.numpy()[0] * 255).astype(\"uint8\"))\n",
        "#display(imgt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XZxxezOlF_A0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# loade My test set to make my test loader\n",
        "my_test_loader = torch.utils.data.DataLoader(dataset=mydataT,\n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vIrLyMYNGCGp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Convolutional neural network (two convolutional layers)\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.fc = nn.Linear(7*7*32, num_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "model = ConvNet(num_classes).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kcebFOUWGE7P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Uw8xrsotJe4G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1.1 experiment on 100 size trainning set"
      ]
    },
    {
      "metadata": {
        "id": "ZhA9XSDGG9ag",
        "colab_type": "code",
        "outputId": "73686e26-ea8f-4cdd-f284-d1b141cf77f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "# Hyper parameters\n",
        "num_epochs = 5\n",
        "num_classes = 10\n",
        "batch_size = 50\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Data loader\n",
        "\n",
        "# loade trainning MNIST set \n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)\n",
        "\n",
        "# Train the model\n",
        "total_step = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        if i > 1:\n",
        "            break\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if (i+1) % 1 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Step [1/1200], Loss: 0.0746\n",
            "Epoch [1/5], Step [2/1200], Loss: 0.1215\n",
            "Epoch [2/5], Step [1/1200], Loss: 0.0581\n",
            "Epoch [2/5], Step [2/1200], Loss: 0.0184\n",
            "Epoch [3/5], Step [1/1200], Loss: 0.1512\n",
            "Epoch [3/5], Step [2/1200], Loss: 0.2745\n",
            "Epoch [4/5], Step [1/1200], Loss: 0.0497\n",
            "Epoch [4/5], Step [2/1200], Loss: 0.0699\n",
            "Epoch [5/5], Step [1/1200], Loss: 0.3059\n",
            "Epoch [5/5], Step [2/1200], Loss: 0.0232\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nOI-LHJgHVvw",
        "colab_type": "code",
        "outputId": "7287f40c-f36b-45d0-b62d-828209ed0e82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Test the model on myDataSet\n",
        "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in my_test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Test Accuracy of 100 images trained model on the my dataset: {} %'.format(100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy of 100 images trained model on the my dataset: 66.66666666666667 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IkM8HvalLrqI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1.2 experiment on 250 size trainning set"
      ]
    },
    {
      "metadata": {
        "id": "2gtvv5LnHc0I",
        "colab_type": "code",
        "outputId": "7ae53c6a-0daf-4fe5-a268-797ddae0dfb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "num_epochs = 5\n",
        "num_classes = 10\n",
        "batch_size = 50\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Data loader\n",
        "\n",
        "# loade trainning MNIST set \n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)\n",
        "\n",
        "# Train the model\n",
        "total_step = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        if i > 4:\n",
        "            break\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if (i+1) % 1 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Step [1/1200], Loss: 0.0706\n",
            "Epoch [1/5], Step [2/1200], Loss: 0.1659\n",
            "Epoch [1/5], Step [3/1200], Loss: 0.0552\n",
            "Epoch [1/5], Step [4/1200], Loss: 0.2078\n",
            "Epoch [1/5], Step [5/1200], Loss: 0.0696\n",
            "Epoch [2/5], Step [1/1200], Loss: 0.0255\n",
            "Epoch [2/5], Step [2/1200], Loss: 0.0501\n",
            "Epoch [2/5], Step [3/1200], Loss: 0.1045\n",
            "Epoch [2/5], Step [4/1200], Loss: 0.0424\n",
            "Epoch [2/5], Step [5/1200], Loss: 0.0489\n",
            "Epoch [3/5], Step [1/1200], Loss: 0.1225\n",
            "Epoch [3/5], Step [2/1200], Loss: 0.0569\n",
            "Epoch [3/5], Step [3/1200], Loss: 0.1091\n",
            "Epoch [3/5], Step [4/1200], Loss: 0.1069\n",
            "Epoch [3/5], Step [5/1200], Loss: 0.0500\n",
            "Epoch [4/5], Step [1/1200], Loss: 0.0635\n",
            "Epoch [4/5], Step [2/1200], Loss: 0.1186\n",
            "Epoch [4/5], Step [3/1200], Loss: 0.0227\n",
            "Epoch [4/5], Step [4/1200], Loss: 0.2184\n",
            "Epoch [4/5], Step [5/1200], Loss: 0.1934\n",
            "Epoch [5/5], Step [1/1200], Loss: 0.0969\n",
            "Epoch [5/5], Step [2/1200], Loss: 0.1210\n",
            "Epoch [5/5], Step [3/1200], Loss: 0.0166\n",
            "Epoch [5/5], Step [4/1200], Loss: 0.0332\n",
            "Epoch [5/5], Step [5/1200], Loss: 0.1518\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4BE2GZDZHyOY",
        "colab_type": "code",
        "outputId": "744e2271-4267-44c2-9692-49bea2a08d6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Test the model on MNIST dataset\n",
        "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in my_test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Test Accuracy of 250 images trained model on the my dataset: {} %'.format(100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy of 250 images trained model on the my dataset: 68.33333333333333 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Loj16xeRLw97",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1.3 experiment on 500 size trainning set"
      ]
    },
    {
      "metadata": {
        "id": "U7YbkoLeIFq7",
        "colab_type": "code",
        "outputId": "abda6d66-7da1-41a5-a299-c4731158a6cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "cell_type": "code",
      "source": [
        "# Hyper parameters\n",
        "num_epochs = 5\n",
        "num_classes = 10\n",
        "batch_size = 50\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Data loader\n",
        "\n",
        "# loade trainning MNIST set \n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)\n",
        "\n",
        "# Train the model\n",
        "total_step = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        if i > 9:\n",
        "            break\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if (i+1) % 1 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Step [1/1200], Loss: 0.0568\n",
            "Epoch [1/5], Step [2/1200], Loss: 0.1204\n",
            "Epoch [1/5], Step [3/1200], Loss: 0.0863\n",
            "Epoch [1/5], Step [4/1200], Loss: 0.0193\n",
            "Epoch [1/5], Step [5/1200], Loss: 0.0751\n",
            "Epoch [1/5], Step [6/1200], Loss: 0.0257\n",
            "Epoch [1/5], Step [7/1200], Loss: 0.1827\n",
            "Epoch [1/5], Step [8/1200], Loss: 0.1464\n",
            "Epoch [1/5], Step [9/1200], Loss: 0.0615\n",
            "Epoch [1/5], Step [10/1200], Loss: 0.0615\n",
            "Epoch [2/5], Step [1/1200], Loss: 0.0896\n",
            "Epoch [2/5], Step [2/1200], Loss: 0.0287\n",
            "Epoch [2/5], Step [3/1200], Loss: 0.1033\n",
            "Epoch [2/5], Step [4/1200], Loss: 0.0350\n",
            "Epoch [2/5], Step [5/1200], Loss: 0.1826\n",
            "Epoch [2/5], Step [6/1200], Loss: 0.0317\n",
            "Epoch [2/5], Step [7/1200], Loss: 0.0823\n",
            "Epoch [2/5], Step [8/1200], Loss: 0.1101\n",
            "Epoch [2/5], Step [9/1200], Loss: 0.1387\n",
            "Epoch [2/5], Step [10/1200], Loss: 0.1394\n",
            "Epoch [3/5], Step [1/1200], Loss: 0.0379\n",
            "Epoch [3/5], Step [2/1200], Loss: 0.0287\n",
            "Epoch [3/5], Step [3/1200], Loss: 0.0618\n",
            "Epoch [3/5], Step [4/1200], Loss: 0.1528\n",
            "Epoch [3/5], Step [5/1200], Loss: 0.1078\n",
            "Epoch [3/5], Step [6/1200], Loss: 0.3177\n",
            "Epoch [3/5], Step [7/1200], Loss: 0.0551\n",
            "Epoch [3/5], Step [8/1200], Loss: 0.1169\n",
            "Epoch [3/5], Step [9/1200], Loss: 0.0379\n",
            "Epoch [3/5], Step [10/1200], Loss: 0.0129\n",
            "Epoch [4/5], Step [1/1200], Loss: 0.0753\n",
            "Epoch [4/5], Step [2/1200], Loss: 0.1044\n",
            "Epoch [4/5], Step [3/1200], Loss: 0.0712\n",
            "Epoch [4/5], Step [4/1200], Loss: 0.1321\n",
            "Epoch [4/5], Step [5/1200], Loss: 0.0460\n",
            "Epoch [4/5], Step [6/1200], Loss: 0.0998\n",
            "Epoch [4/5], Step [7/1200], Loss: 0.1236\n",
            "Epoch [4/5], Step [8/1200], Loss: 0.2159\n",
            "Epoch [4/5], Step [9/1200], Loss: 0.0520\n",
            "Epoch [4/5], Step [10/1200], Loss: 0.0442\n",
            "Epoch [5/5], Step [1/1200], Loss: 0.0647\n",
            "Epoch [5/5], Step [2/1200], Loss: 0.1449\n",
            "Epoch [5/5], Step [3/1200], Loss: 0.2781\n",
            "Epoch [5/5], Step [4/1200], Loss: 0.0883\n",
            "Epoch [5/5], Step [5/1200], Loss: 0.1453\n",
            "Epoch [5/5], Step [6/1200], Loss: 0.0329\n",
            "Epoch [5/5], Step [7/1200], Loss: 0.1503\n",
            "Epoch [5/5], Step [8/1200], Loss: 0.0326\n",
            "Epoch [5/5], Step [9/1200], Loss: 0.0184\n",
            "Epoch [5/5], Step [10/1200], Loss: 0.0529\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "40P8AqA6II0l",
        "colab_type": "code",
        "outputId": "e89974d5-15d9-4df1-caac-dd194cdff32e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Test the model on myDataSet\n",
        "\n",
        "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in my_test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Test Accuracy of 500 images trained model on the my dataset: {} %'.format(100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy of 500 images trained model on the my dataset: 70.0 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hqhqzm47JWfC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1.4 experiment on 1000 size trainning set\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "IGyV2JUOGHTG",
        "colab_type": "code",
        "outputId": "6340b46c-f1cf-424d-8cde-35afef4d4157",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1717
        }
      },
      "cell_type": "code",
      "source": [
        "# Hyper parameters\n",
        "num_epochs = 5\n",
        "num_classes = 10\n",
        "batch_size = 50\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Data loader\n",
        "\n",
        "# loade trainning MNIST set \n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)\n",
        "\n",
        "# Train the model\n",
        "total_step = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        if i > 19:\n",
        "            break\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if (i+1) % 1 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Step [1/1200], Loss: 0.0120\n",
            "Epoch [1/5], Step [2/1200], Loss: 0.1557\n",
            "Epoch [1/5], Step [3/1200], Loss: 0.0498\n",
            "Epoch [1/5], Step [4/1200], Loss: 0.0168\n",
            "Epoch [1/5], Step [5/1200], Loss: 0.0265\n",
            "Epoch [1/5], Step [6/1200], Loss: 0.0753\n",
            "Epoch [1/5], Step [7/1200], Loss: 0.0644\n",
            "Epoch [1/5], Step [8/1200], Loss: 0.0198\n",
            "Epoch [1/5], Step [9/1200], Loss: 0.1191\n",
            "Epoch [1/5], Step [10/1200], Loss: 0.0466\n",
            "Epoch [1/5], Step [11/1200], Loss: 0.3127\n",
            "Epoch [1/5], Step [12/1200], Loss: 0.0728\n",
            "Epoch [1/5], Step [13/1200], Loss: 0.1182\n",
            "Epoch [1/5], Step [14/1200], Loss: 0.2562\n",
            "Epoch [1/5], Step [15/1200], Loss: 0.0844\n",
            "Epoch [1/5], Step [16/1200], Loss: 0.0859\n",
            "Epoch [1/5], Step [17/1200], Loss: 0.1902\n",
            "Epoch [1/5], Step [18/1200], Loss: 0.0768\n",
            "Epoch [1/5], Step [19/1200], Loss: 0.0727\n",
            "Epoch [1/5], Step [20/1200], Loss: 0.0614\n",
            "Epoch [2/5], Step [1/1200], Loss: 0.0515\n",
            "Epoch [2/5], Step [2/1200], Loss: 0.0375\n",
            "Epoch [2/5], Step [3/1200], Loss: 0.0705\n",
            "Epoch [2/5], Step [4/1200], Loss: 0.0562\n",
            "Epoch [2/5], Step [5/1200], Loss: 0.0729\n",
            "Epoch [2/5], Step [6/1200], Loss: 0.1545\n",
            "Epoch [2/5], Step [7/1200], Loss: 0.0767\n",
            "Epoch [2/5], Step [8/1200], Loss: 0.0307\n",
            "Epoch [2/5], Step [9/1200], Loss: 0.0711\n",
            "Epoch [2/5], Step [10/1200], Loss: 0.1464\n",
            "Epoch [2/5], Step [11/1200], Loss: 0.0440\n",
            "Epoch [2/5], Step [12/1200], Loss: 0.0433\n",
            "Epoch [2/5], Step [13/1200], Loss: 0.0755\n",
            "Epoch [2/5], Step [14/1200], Loss: 0.0639\n",
            "Epoch [2/5], Step [15/1200], Loss: 0.0332\n",
            "Epoch [2/5], Step [16/1200], Loss: 0.0135\n",
            "Epoch [2/5], Step [17/1200], Loss: 0.1410\n",
            "Epoch [2/5], Step [18/1200], Loss: 0.0319\n",
            "Epoch [2/5], Step [19/1200], Loss: 0.0082\n",
            "Epoch [2/5], Step [20/1200], Loss: 0.0108\n",
            "Epoch [3/5], Step [1/1200], Loss: 0.1283\n",
            "Epoch [3/5], Step [2/1200], Loss: 0.1578\n",
            "Epoch [3/5], Step [3/1200], Loss: 0.0229\n",
            "Epoch [3/5], Step [4/1200], Loss: 0.0231\n",
            "Epoch [3/5], Step [5/1200], Loss: 0.0510\n",
            "Epoch [3/5], Step [6/1200], Loss: 0.0162\n",
            "Epoch [3/5], Step [7/1200], Loss: 0.1096\n",
            "Epoch [3/5], Step [8/1200], Loss: 0.0789\n",
            "Epoch [3/5], Step [9/1200], Loss: 0.0525\n",
            "Epoch [3/5], Step [10/1200], Loss: 0.0163\n",
            "Epoch [3/5], Step [11/1200], Loss: 0.0128\n",
            "Epoch [3/5], Step [12/1200], Loss: 0.0892\n",
            "Epoch [3/5], Step [13/1200], Loss: 0.0739\n",
            "Epoch [3/5], Step [14/1200], Loss: 0.0578\n",
            "Epoch [3/5], Step [15/1200], Loss: 0.0601\n",
            "Epoch [3/5], Step [16/1200], Loss: 0.0671\n",
            "Epoch [3/5], Step [17/1200], Loss: 0.0828\n",
            "Epoch [3/5], Step [18/1200], Loss: 0.0077\n",
            "Epoch [3/5], Step [19/1200], Loss: 0.0269\n",
            "Epoch [3/5], Step [20/1200], Loss: 0.1492\n",
            "Epoch [4/5], Step [1/1200], Loss: 0.0319\n",
            "Epoch [4/5], Step [2/1200], Loss: 0.0223\n",
            "Epoch [4/5], Step [3/1200], Loss: 0.0588\n",
            "Epoch [4/5], Step [4/1200], Loss: 0.0755\n",
            "Epoch [4/5], Step [5/1200], Loss: 0.0371\n",
            "Epoch [4/5], Step [6/1200], Loss: 0.0809\n",
            "Epoch [4/5], Step [7/1200], Loss: 0.0213\n",
            "Epoch [4/5], Step [8/1200], Loss: 0.0880\n",
            "Epoch [4/5], Step [9/1200], Loss: 0.0954\n",
            "Epoch [4/5], Step [10/1200], Loss: 0.1407\n",
            "Epoch [4/5], Step [11/1200], Loss: 0.0300\n",
            "Epoch [4/5], Step [12/1200], Loss: 0.1095\n",
            "Epoch [4/5], Step [13/1200], Loss: 0.0202\n",
            "Epoch [4/5], Step [14/1200], Loss: 0.0151\n",
            "Epoch [4/5], Step [15/1200], Loss: 0.0352\n",
            "Epoch [4/5], Step [16/1200], Loss: 0.0646\n",
            "Epoch [4/5], Step [17/1200], Loss: 0.1348\n",
            "Epoch [4/5], Step [18/1200], Loss: 0.0856\n",
            "Epoch [4/5], Step [19/1200], Loss: 0.0057\n",
            "Epoch [4/5], Step [20/1200], Loss: 0.1028\n",
            "Epoch [5/5], Step [1/1200], Loss: 0.0106\n",
            "Epoch [5/5], Step [2/1200], Loss: 0.0162\n",
            "Epoch [5/5], Step [3/1200], Loss: 0.0203\n",
            "Epoch [5/5], Step [4/1200], Loss: 0.0509\n",
            "Epoch [5/5], Step [5/1200], Loss: 0.0216\n",
            "Epoch [5/5], Step [6/1200], Loss: 0.1055\n",
            "Epoch [5/5], Step [7/1200], Loss: 0.0246\n",
            "Epoch [5/5], Step [8/1200], Loss: 0.0530\n",
            "Epoch [5/5], Step [9/1200], Loss: 0.1653\n",
            "Epoch [5/5], Step [10/1200], Loss: 0.3039\n",
            "Epoch [5/5], Step [11/1200], Loss: 0.0216\n",
            "Epoch [5/5], Step [12/1200], Loss: 0.0419\n",
            "Epoch [5/5], Step [13/1200], Loss: 0.0314\n",
            "Epoch [5/5], Step [14/1200], Loss: 0.0686\n",
            "Epoch [5/5], Step [15/1200], Loss: 0.0600\n",
            "Epoch [5/5], Step [16/1200], Loss: 0.2127\n",
            "Epoch [5/5], Step [17/1200], Loss: 0.0256\n",
            "Epoch [5/5], Step [18/1200], Loss: 0.0451\n",
            "Epoch [5/5], Step [19/1200], Loss: 0.1293\n",
            "Epoch [5/5], Step [20/1200], Loss: 0.0513\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6y_HLukxGLNI",
        "colab_type": "code",
        "outputId": "34d0c566-89ca-464a-99a4-033ad66ed429",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Test the model on myDataSet\n",
        "\n",
        "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in my_test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Test Accuracy of 50 images trained model on the my dataset: {} %'.format(100 * correct / total))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy of 50 images trained model on the my dataset: 68.33333333333333 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eY9UR5pCL22B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1.5 experiment on 60000 size trainning set"
      ]
    },
    {
      "metadata": {
        "id": "Y5dlq_ClINGp",
        "colab_type": "code",
        "outputId": "1f3a5e7f-c22b-48a5-fe22-8c6f934d93ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "cell_type": "code",
      "source": [
        "# Hyper parameters\n",
        "num_epochs = 5\n",
        "num_classes = 10\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Data loader\n",
        "\n",
        "# loade trainning MNIST set \n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)\n",
        "# Train the model\n",
        "total_step = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if (i+1) % 100 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Step [100/600], Loss: 0.2975\n",
            "Epoch [1/5], Step [200/600], Loss: 0.1002\n",
            "Epoch [1/5], Step [300/600], Loss: 0.1049\n",
            "Epoch [1/5], Step [400/600], Loss: 0.0836\n",
            "Epoch [1/5], Step [500/600], Loss: 0.1222\n",
            "Epoch [1/5], Step [600/600], Loss: 0.0575\n",
            "Epoch [2/5], Step [100/600], Loss: 0.0124\n",
            "Epoch [2/5], Step [200/600], Loss: 0.0734\n",
            "Epoch [2/5], Step [300/600], Loss: 0.0132\n",
            "Epoch [2/5], Step [400/600], Loss: 0.0182\n",
            "Epoch [2/5], Step [500/600], Loss: 0.0949\n",
            "Epoch [2/5], Step [600/600], Loss: 0.1136\n",
            "Epoch [3/5], Step [100/600], Loss: 0.0144\n",
            "Epoch [3/5], Step [200/600], Loss: 0.0502\n",
            "Epoch [3/5], Step [300/600], Loss: 0.0173\n",
            "Epoch [3/5], Step [400/600], Loss: 0.0579\n",
            "Epoch [3/5], Step [500/600], Loss: 0.0267\n",
            "Epoch [3/5], Step [600/600], Loss: 0.0393\n",
            "Epoch [4/5], Step [100/600], Loss: 0.0037\n",
            "Epoch [4/5], Step [200/600], Loss: 0.0056\n",
            "Epoch [4/5], Step [300/600], Loss: 0.0556\n",
            "Epoch [4/5], Step [400/600], Loss: 0.0237\n",
            "Epoch [4/5], Step [500/600], Loss: 0.0268\n",
            "Epoch [4/5], Step [600/600], Loss: 0.0188\n",
            "Epoch [5/5], Step [100/600], Loss: 0.0127\n",
            "Epoch [5/5], Step [200/600], Loss: 0.0079\n",
            "Epoch [5/5], Step [300/600], Loss: 0.0035\n",
            "Epoch [5/5], Step [400/600], Loss: 0.0219\n",
            "Epoch [5/5], Step [500/600], Loss: 0.0375\n",
            "Epoch [5/5], Step [600/600], Loss: 0.0393\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9CZSaUfQISue",
        "colab_type": "code",
        "outputId": "38a7aa21-0da1-47aa-acb7-a35e3730934d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Test the model on myDataSet\n",
        "\n",
        "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in my_test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Test Accuracy of 60000 images trained model on the my dataset: {} %'.format(100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy of 60000 images trained model on the my dataset: 73.33333333333333 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EhN2wqUrL06W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}