{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Xinyi(Blanca) Bai lab8a.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "7HjUEg_rMSrs",
        "usMFBvtccgzw",
        "E_hhhYa4dB6y",
        "24NmeOpndIWP",
        "-1Ja0YdU1Ihc",
        "7sAIm-Hp0TPt",
        "s_qIN9XG2yzi",
        "OdurHY95251T",
        "GdWHimbyUuJM",
        "V_TK-o203vVV",
        "13MwZLXl2HaZ",
        "7uZ7aRyl-Ugr",
        "Z6N6vJTOMzd1",
        "L4iUhLMkM6G0",
        "jhZPgC5DgNBT",
        "i3wZjtGcE264",
        "h27D84QOLCkg",
        "mrYQzIySK7j8",
        "t8fs1WSMdLtM",
        "yM9Lgi21dUg1",
        "U0m3hO4KTjcA",
        "B49pQpQAc_f2",
        "4drIecTQeZn2",
        "3_mf-OiiyQTr",
        "8PP-GMwc01xU",
        "waM6jXyH1TCE",
        "AWa8E9MV2B2f",
        "PlVboYdO8BGP",
        "ACu2zUXt8QWB",
        "u1DPR1w78wJD",
        "N_B3uXbuhA2d"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wwwbxy123/Handwrite-recognition-CNN-model-explores-with-Pytorch-Keras-and-my-models-/blob/master/Xinyi(Blanca)_Bai_lab8a.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "5Z5o_Kxya6bG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Lab 8 Convolutional Neural Network\n"
      ]
    },
    {
      "metadata": {
        "id": "oLR5TYEEa-7w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Name: Xinyi (Blanca) Bai ID:xb52"
      ]
    },
    {
      "metadata": {
        "id": "ZlzxhSjbbET9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1. Pytorch Learning Curves"
      ]
    },
    {
      "metadata": {
        "id": "7HjUEg_rMSrs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### prepare the model "
      ]
    },
    {
      "metadata": {
        "id": "n7CM-qHXbPic",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this part, we explore the impact of the training dataset size on system performance. First, we train the model given in the PyTorch Tutorial with at least five different size training datasets. Then, we plot the accuracy achieved on the full test dataset for each trained model.\n"
      ]
    },
    {
      "metadata": {
        "id": "9MHeyRvqbUX8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For the analysis of this experiment we plot the accuracy achieved on the full test dataset for each trained model. On the same graph, for each trained model, we plot the accuracy achieved with the corresponding training dataset; every graph include a legend for the two plots."
      ]
    },
    {
      "metadata": {
        "id": "HsvWt31RaJzo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#install torch in google colab\n",
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L22xxgqTaUtC",
        "colab_type": "code",
        "outputId": "04adf105-43b0-4b47-b12e-a53d5050e42e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.4.1\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_DiRsNBMagyE",
        "colab_type": "code",
        "outputId": "5488f3a9-1b17-454b-b810-b4d2d8abceda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "#initialization\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper parameters\n",
        "num_epochs = 5\n",
        "num_classes = 10\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "# MNIST dataset\n",
        "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=None)\n",
        "len(mnist_trainset)\n",
        "print(mnist_trainset)\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data/',\n",
        "                                           train=True, \n",
        "                                           transform=transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data/',\n",
        "                                          train=False, \n",
        "                                          transform=transforms.ToTensor())\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n",
            "Dataset MNIST\n",
            "    Number of datapoints: 60000\n",
            "    Split: train\n",
            "    Root Location: ./data\n",
            "    Transforms (if any): None\n",
            "    Target Transforms (if any): None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_Lc23L-laxSJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Convolutional neural network (two convolutional layers)\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.fc = nn.Linear(7*7*32, num_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "model = ConvNet(num_classes).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OCYjmomva01n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_jquyrznThDS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# loade test MNIST set \n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "usMFBvtccgzw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.1 experiment on 250 size trainning set"
      ]
    },
    {
      "metadata": {
        "id": "QZhX4flTyVVL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For training on 250 samples,  I reduce the batch size to 50 and in the training loop, and break after running for 5 iterations. "
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "a49035df-5fc5-4527-a073-f3586b5fff68",
        "id": "cjDA-0x4i6ls",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "cell_type": "code",
      "source": [
        "# Hyper parameters\n",
        "num_epochs = 5\n",
        "num_classes = 10\n",
        "batch_size = 50\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Data loader\n",
        "\n",
        "# loade trainning MNIST set \n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)\n",
        "\n",
        "# Train the model\n",
        "total_step = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        if i > 4:\n",
        "            break\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if (i+1) % 1 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Step [1/1200], Loss: 0.1038\n",
            "Epoch [1/5], Step [2/1200], Loss: 0.0147\n",
            "Epoch [1/5], Step [3/1200], Loss: 0.0533\n",
            "Epoch [1/5], Step [4/1200], Loss: 0.1303\n",
            "Epoch [1/5], Step [5/1200], Loss: 0.0330\n",
            "Epoch [2/5], Step [1/1200], Loss: 0.0761\n",
            "Epoch [2/5], Step [2/1200], Loss: 0.0373\n",
            "Epoch [2/5], Step [3/1200], Loss: 0.1423\n",
            "Epoch [2/5], Step [4/1200], Loss: 0.0776\n",
            "Epoch [2/5], Step [5/1200], Loss: 0.0387\n",
            "Epoch [3/5], Step [1/1200], Loss: 0.0361\n",
            "Epoch [3/5], Step [2/1200], Loss: 0.0608\n",
            "Epoch [3/5], Step [3/1200], Loss: 0.0709\n",
            "Epoch [3/5], Step [4/1200], Loss: 0.2585\n",
            "Epoch [3/5], Step [5/1200], Loss: 0.0232\n",
            "Epoch [4/5], Step [1/1200], Loss: 0.2701\n",
            "Epoch [4/5], Step [2/1200], Loss: 0.0628\n",
            "Epoch [4/5], Step [3/1200], Loss: 0.1828\n",
            "Epoch [4/5], Step [4/1200], Loss: 0.0443\n",
            "Epoch [4/5], Step [5/1200], Loss: 0.0405\n",
            "Epoch [5/5], Step [1/1200], Loss: 0.1535\n",
            "Epoch [5/5], Step [2/1200], Loss: 0.0321\n",
            "Epoch [5/5], Step [3/1200], Loss: 0.0860\n",
            "Epoch [5/5], Step [4/1200], Loss: 0.0752\n",
            "Epoch [5/5], Step [5/1200], Loss: 0.2405\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "izUVIltoc_7_",
        "colab_type": "code",
        "outputId": "289aea19-4db9-406e-d9a0-f5757692625f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Test the model on MNIST dataset\n",
        "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Test Accuracy of 250 images trained model on the MNIST fulltestset: {} %'.format(100 * correct / total))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy of 250 images trained model on the MNIST fulltestset: 97.34 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "E_hhhYa4dB6y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.2 experiment on 60000 size trainning set"
      ]
    },
    {
      "metadata": {
        "id": "jhoNgH9Obf6E",
        "colab_type": "code",
        "outputId": "3f4c70de-8c76-42de-a5d9-06e95b524a69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "cell_type": "code",
      "source": [
        "# Hyper parameters\n",
        "num_epochs = 5\n",
        "num_classes = 10\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Data loader\n",
        "\n",
        "# loade trainning MNIST set \n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)\n",
        "# Train the model\n",
        "total_step = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if (i+1) % 100 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Step [100/600], Loss: 0.0015\n",
            "Epoch [1/5], Step [200/600], Loss: 0.0092\n",
            "Epoch [1/5], Step [300/600], Loss: 0.0043\n",
            "Epoch [1/5], Step [400/600], Loss: 0.0006\n",
            "Epoch [1/5], Step [500/600], Loss: 0.0015\n",
            "Epoch [1/5], Step [600/600], Loss: 0.0000\n",
            "Epoch [2/5], Step [100/600], Loss: 0.0072\n",
            "Epoch [2/5], Step [200/600], Loss: 0.0016\n",
            "Epoch [2/5], Step [300/600], Loss: 0.0089\n",
            "Epoch [2/5], Step [400/600], Loss: 0.0002\n",
            "Epoch [2/5], Step [500/600], Loss: 0.0003\n",
            "Epoch [2/5], Step [600/600], Loss: 0.0029\n",
            "Epoch [3/5], Step [100/600], Loss: 0.0185\n",
            "Epoch [3/5], Step [200/600], Loss: 0.0102\n",
            "Epoch [3/5], Step [300/600], Loss: 0.0504\n",
            "Epoch [3/5], Step [400/600], Loss: 0.0001\n",
            "Epoch [3/5], Step [500/600], Loss: 0.0015\n",
            "Epoch [3/5], Step [600/600], Loss: 0.0012\n",
            "Epoch [4/5], Step [100/600], Loss: 0.0032\n",
            "Epoch [4/5], Step [200/600], Loss: 0.0030\n",
            "Epoch [4/5], Step [300/600], Loss: 0.0001\n",
            "Epoch [4/5], Step [400/600], Loss: 0.0010\n",
            "Epoch [4/5], Step [500/600], Loss: 0.0003\n",
            "Epoch [4/5], Step [600/600], Loss: 0.0002\n",
            "Epoch [5/5], Step [100/600], Loss: 0.0004\n",
            "Epoch [5/5], Step [200/600], Loss: 0.0002\n",
            "Epoch [5/5], Step [300/600], Loss: 0.0015\n",
            "Epoch [5/5], Step [400/600], Loss: 0.0178\n",
            "Epoch [5/5], Step [500/600], Loss: 0.0099\n",
            "Epoch [5/5], Step [600/600], Loss: 0.0007\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9Kta38byb1I0",
        "colab_type": "code",
        "outputId": "9c12a841-dcfb-40dc-c1ad-9c2eb87627a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Test the model on MNIST dataset\n",
        "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Test Accuracy of 60000 images trained model on the MNIST fulltestset:  {} %'.format(100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy of 60000 images trained model on the MNIST fulltestset:  99.16 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "24NmeOpndIWP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.3 experiment on 100 size trainning set"
      ]
    },
    {
      "metadata": {
        "id": "pbsFA-E3zudp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For trainning on 100 samples, I reduce the batch size to 20 and in the training loop, and break after running for 5 iterations."
      ]
    },
    {
      "metadata": {
        "id": "5Dy6AjyQjW23",
        "colab_type": "code",
        "outputId": "b4e5e687-fef7-4536-e70e-e0fee7c29fe2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "# Hyper parameters\n",
        "num_epochs = 5\n",
        "num_classes = 10\n",
        "batch_size = 50\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Data loader\n",
        "\n",
        "# loade trainning MNIST set \n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)\n",
        "\n",
        "# Train the model\n",
        "total_step = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        if i > 1:\n",
        "            break\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if (i+1) % 1 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Step [1/1200], Loss: 0.0722\n",
            "Epoch [1/5], Step [2/1200], Loss: 0.0147\n",
            "Epoch [2/5], Step [1/1200], Loss: 0.1786\n",
            "Epoch [2/5], Step [2/1200], Loss: 0.1091\n",
            "Epoch [3/5], Step [1/1200], Loss: 0.0816\n",
            "Epoch [3/5], Step [2/1200], Loss: 0.0406\n",
            "Epoch [4/5], Step [1/1200], Loss: 0.1090\n",
            "Epoch [4/5], Step [2/1200], Loss: 0.0348\n",
            "Epoch [5/5], Step [1/1200], Loss: 0.0416\n",
            "Epoch [5/5], Step [2/1200], Loss: 0.2683\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "13yQvxvzykCZ",
        "colab_type": "code",
        "outputId": "d12eb6dc-1cc4-441c-a92d-6484036d6deb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Test the model on MNIST dataset\n",
        "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Test Accuracy of 100 images trained model on the MNIST fulltestset: {} %'.format(100 * correct / total))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy of 100 images trained model on the MNIST fulltestset: 96.96 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wBoC5hPwzKTO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "I try another way to use 100 test images, I reduce the batch size to 50 and in the training loop, and break after running for 2 iterations."
      ]
    },
    {
      "metadata": {
        "id": "-1Ja0YdU1Ihc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.4 Experiment on 500 size trainning set"
      ]
    },
    {
      "metadata": {
        "id": "n6Njb63A1hbC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For trainning on 500 samples, I reduce the batch size to 50 and in the training loop, and break after running for 10 iterations."
      ]
    },
    {
      "metadata": {
        "id": "erorUQoY1k0D",
        "colab_type": "code",
        "outputId": "9e2e2e25-8d73-4916-e84d-2e1c331b2e89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "cell_type": "code",
      "source": [
        "# Hyper parameters\n",
        "num_epochs = 5\n",
        "num_classes = 10\n",
        "batch_size = 50\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Data loader\n",
        "\n",
        "# loade trainning MNIST set \n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)\n",
        "\n",
        "# Train the model\n",
        "total_step = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        if i > 9:\n",
        "            break\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if (i+1) % 1 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Step [1/1200], Loss: 0.0599\n",
            "Epoch [1/5], Step [2/1200], Loss: 0.0912\n",
            "Epoch [1/5], Step [3/1200], Loss: 0.0453\n",
            "Epoch [1/5], Step [4/1200], Loss: 0.3845\n",
            "Epoch [1/5], Step [5/1200], Loss: 0.1963\n",
            "Epoch [1/5], Step [6/1200], Loss: 0.0493\n",
            "Epoch [1/5], Step [7/1200], Loss: 0.1884\n",
            "Epoch [1/5], Step [8/1200], Loss: 0.1996\n",
            "Epoch [1/5], Step [9/1200], Loss: 0.0225\n",
            "Epoch [1/5], Step [10/1200], Loss: 0.0335\n",
            "Epoch [2/5], Step [1/1200], Loss: 0.0984\n",
            "Epoch [2/5], Step [2/1200], Loss: 0.1915\n",
            "Epoch [2/5], Step [3/1200], Loss: 0.0806\n",
            "Epoch [2/5], Step [4/1200], Loss: 0.1534\n",
            "Epoch [2/5], Step [5/1200], Loss: 0.1624\n",
            "Epoch [2/5], Step [6/1200], Loss: 0.2446\n",
            "Epoch [2/5], Step [7/1200], Loss: 0.0835\n",
            "Epoch [2/5], Step [8/1200], Loss: 0.0458\n",
            "Epoch [2/5], Step [9/1200], Loss: 0.1156\n",
            "Epoch [2/5], Step [10/1200], Loss: 0.2022\n",
            "Epoch [3/5], Step [1/1200], Loss: 0.2288\n",
            "Epoch [3/5], Step [2/1200], Loss: 0.1137\n",
            "Epoch [3/5], Step [3/1200], Loss: 0.0117\n",
            "Epoch [3/5], Step [4/1200], Loss: 0.0419\n",
            "Epoch [3/5], Step [5/1200], Loss: 0.0294\n",
            "Epoch [3/5], Step [6/1200], Loss: 0.1057\n",
            "Epoch [3/5], Step [7/1200], Loss: 0.0586\n",
            "Epoch [3/5], Step [8/1200], Loss: 0.0430\n",
            "Epoch [3/5], Step [9/1200], Loss: 0.1252\n",
            "Epoch [3/5], Step [10/1200], Loss: 0.0780\n",
            "Epoch [4/5], Step [1/1200], Loss: 0.0685\n",
            "Epoch [4/5], Step [2/1200], Loss: 0.1433\n",
            "Epoch [4/5], Step [3/1200], Loss: 0.0482\n",
            "Epoch [4/5], Step [4/1200], Loss: 0.0856\n",
            "Epoch [4/5], Step [5/1200], Loss: 0.1392\n",
            "Epoch [4/5], Step [6/1200], Loss: 0.0546\n",
            "Epoch [4/5], Step [7/1200], Loss: 0.0262\n",
            "Epoch [4/5], Step [8/1200], Loss: 0.1700\n",
            "Epoch [4/5], Step [9/1200], Loss: 0.0165\n",
            "Epoch [4/5], Step [10/1200], Loss: 0.0319\n",
            "Epoch [5/5], Step [1/1200], Loss: 0.1612\n",
            "Epoch [5/5], Step [2/1200], Loss: 0.0191\n",
            "Epoch [5/5], Step [3/1200], Loss: 0.0612\n",
            "Epoch [5/5], Step [4/1200], Loss: 0.1419\n",
            "Epoch [5/5], Step [5/1200], Loss: 0.0474\n",
            "Epoch [5/5], Step [6/1200], Loss: 0.2092\n",
            "Epoch [5/5], Step [7/1200], Loss: 0.0915\n",
            "Epoch [5/5], Step [8/1200], Loss: 0.1428\n",
            "Epoch [5/5], Step [9/1200], Loss: 0.0505\n",
            "Epoch [5/5], Step [10/1200], Loss: 0.1797\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UWkf_U-w1qVR",
        "colab_type": "code",
        "outputId": "869900ef-84c7-42cd-d7e2-bfa659dcf913",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Test the model on MNIST dataset\n",
        "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Test Accuracy of 500 images trained model on the MNIST fulltestset {} %'.format(100 * correct / total))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy of 500 images trained model on the MNIST fulltestset 96.37 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7sAIm-Hp0TPt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.5 Experiment on 1000 size trainning set"
      ]
    },
    {
      "metadata": {
        "id": "0kU0JeFX0b8c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For trainning on 1000 samples, I reduce the batch size to 50 and in the training loop, and break after running for 1 iterations."
      ]
    },
    {
      "metadata": {
        "id": "G0uTlZU20Bcs",
        "colab_type": "code",
        "outputId": "f120ac85-683d-4a0d-b5f3-bacbb38120f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1717
        }
      },
      "cell_type": "code",
      "source": [
        "# Hyper parameters\n",
        "num_epochs = 5\n",
        "num_classes = 10\n",
        "batch_size = 50\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Data loader\n",
        "\n",
        "# loade trainning MNIST set \n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)\n",
        "\n",
        "# Train the model\n",
        "total_step = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        if i > 19:\n",
        "            break\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if (i+1) % 1 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Step [1/1200], Loss: 0.2157\n",
            "Epoch [1/5], Step [2/1200], Loss: 0.1117\n",
            "Epoch [1/5], Step [3/1200], Loss: 0.1269\n",
            "Epoch [1/5], Step [4/1200], Loss: 0.3519\n",
            "Epoch [1/5], Step [5/1200], Loss: 0.4409\n",
            "Epoch [1/5], Step [6/1200], Loss: 0.1794\n",
            "Epoch [1/5], Step [7/1200], Loss: 0.2232\n",
            "Epoch [1/5], Step [8/1200], Loss: 0.0731\n",
            "Epoch [1/5], Step [9/1200], Loss: 0.0976\n",
            "Epoch [1/5], Step [10/1200], Loss: 0.2520\n",
            "Epoch [1/5], Step [11/1200], Loss: 0.2931\n",
            "Epoch [1/5], Step [12/1200], Loss: 0.2557\n",
            "Epoch [1/5], Step [13/1200], Loss: 0.2141\n",
            "Epoch [1/5], Step [14/1200], Loss: 0.1530\n",
            "Epoch [1/5], Step [15/1200], Loss: 0.1124\n",
            "Epoch [1/5], Step [16/1200], Loss: 0.1799\n",
            "Epoch [1/5], Step [17/1200], Loss: 0.3999\n",
            "Epoch [1/5], Step [18/1200], Loss: 0.1780\n",
            "Epoch [1/5], Step [19/1200], Loss: 0.2943\n",
            "Epoch [1/5], Step [20/1200], Loss: 0.1722\n",
            "Epoch [2/5], Step [1/1200], Loss: 0.3431\n",
            "Epoch [2/5], Step [2/1200], Loss: 0.1553\n",
            "Epoch [2/5], Step [3/1200], Loss: 0.1118\n",
            "Epoch [2/5], Step [4/1200], Loss: 0.1381\n",
            "Epoch [2/5], Step [5/1200], Loss: 0.1069\n",
            "Epoch [2/5], Step [6/1200], Loss: 0.0829\n",
            "Epoch [2/5], Step [7/1200], Loss: 0.1286\n",
            "Epoch [2/5], Step [8/1200], Loss: 0.2010\n",
            "Epoch [2/5], Step [9/1200], Loss: 0.2945\n",
            "Epoch [2/5], Step [10/1200], Loss: 0.1253\n",
            "Epoch [2/5], Step [11/1200], Loss: 0.1288\n",
            "Epoch [2/5], Step [12/1200], Loss: 0.1755\n",
            "Epoch [2/5], Step [13/1200], Loss: 0.3863\n",
            "Epoch [2/5], Step [14/1200], Loss: 0.2230\n",
            "Epoch [2/5], Step [15/1200], Loss: 0.1621\n",
            "Epoch [2/5], Step [16/1200], Loss: 0.1849\n",
            "Epoch [2/5], Step [17/1200], Loss: 0.1427\n",
            "Epoch [2/5], Step [18/1200], Loss: 0.2358\n",
            "Epoch [2/5], Step [19/1200], Loss: 0.2761\n",
            "Epoch [2/5], Step [20/1200], Loss: 0.0813\n",
            "Epoch [3/5], Step [1/1200], Loss: 0.1960\n",
            "Epoch [3/5], Step [2/1200], Loss: 0.2192\n",
            "Epoch [3/5], Step [3/1200], Loss: 0.1868\n",
            "Epoch [3/5], Step [4/1200], Loss: 0.1386\n",
            "Epoch [3/5], Step [5/1200], Loss: 0.0536\n",
            "Epoch [3/5], Step [6/1200], Loss: 0.2578\n",
            "Epoch [3/5], Step [7/1200], Loss: 0.2112\n",
            "Epoch [3/5], Step [8/1200], Loss: 0.1816\n",
            "Epoch [3/5], Step [9/1200], Loss: 0.1074\n",
            "Epoch [3/5], Step [10/1200], Loss: 0.1948\n",
            "Epoch [3/5], Step [11/1200], Loss: 0.2515\n",
            "Epoch [3/5], Step [12/1200], Loss: 0.1567\n",
            "Epoch [3/5], Step [13/1200], Loss: 0.1882\n",
            "Epoch [3/5], Step [14/1200], Loss: 0.2580\n",
            "Epoch [3/5], Step [15/1200], Loss: 0.1244\n",
            "Epoch [3/5], Step [16/1200], Loss: 0.2248\n",
            "Epoch [3/5], Step [17/1200], Loss: 0.1831\n",
            "Epoch [3/5], Step [18/1200], Loss: 0.0648\n",
            "Epoch [3/5], Step [19/1200], Loss: 0.1784\n",
            "Epoch [3/5], Step [20/1200], Loss: 0.2254\n",
            "Epoch [4/5], Step [1/1200], Loss: 0.1835\n",
            "Epoch [4/5], Step [2/1200], Loss: 0.0822\n",
            "Epoch [4/5], Step [3/1200], Loss: 0.1873\n",
            "Epoch [4/5], Step [4/1200], Loss: 0.0554\n",
            "Epoch [4/5], Step [5/1200], Loss: 0.1185\n",
            "Epoch [4/5], Step [6/1200], Loss: 0.0808\n",
            "Epoch [4/5], Step [7/1200], Loss: 0.0679\n",
            "Epoch [4/5], Step [8/1200], Loss: 0.1334\n",
            "Epoch [4/5], Step [9/1200], Loss: 0.1437\n",
            "Epoch [4/5], Step [10/1200], Loss: 0.1824\n",
            "Epoch [4/5], Step [11/1200], Loss: 0.0548\n",
            "Epoch [4/5], Step [12/1200], Loss: 0.2583\n",
            "Epoch [4/5], Step [13/1200], Loss: 0.1297\n",
            "Epoch [4/5], Step [14/1200], Loss: 0.1139\n",
            "Epoch [4/5], Step [15/1200], Loss: 0.2632\n",
            "Epoch [4/5], Step [16/1200], Loss: 0.0408\n",
            "Epoch [4/5], Step [17/1200], Loss: 0.0553\n",
            "Epoch [4/5], Step [18/1200], Loss: 0.0715\n",
            "Epoch [4/5], Step [19/1200], Loss: 0.0875\n",
            "Epoch [4/5], Step [20/1200], Loss: 0.0755\n",
            "Epoch [5/5], Step [1/1200], Loss: 0.0520\n",
            "Epoch [5/5], Step [2/1200], Loss: 0.0319\n",
            "Epoch [5/5], Step [3/1200], Loss: 0.1075\n",
            "Epoch [5/5], Step [4/1200], Loss: 0.0339\n",
            "Epoch [5/5], Step [5/1200], Loss: 0.0271\n",
            "Epoch [5/5], Step [6/1200], Loss: 0.1398\n",
            "Epoch [5/5], Step [7/1200], Loss: 0.0841\n",
            "Epoch [5/5], Step [8/1200], Loss: 0.0382\n",
            "Epoch [5/5], Step [9/1200], Loss: 0.0604\n",
            "Epoch [5/5], Step [10/1200], Loss: 0.1299\n",
            "Epoch [5/5], Step [11/1200], Loss: 0.0443\n",
            "Epoch [5/5], Step [12/1200], Loss: 0.0249\n",
            "Epoch [5/5], Step [13/1200], Loss: 0.1328\n",
            "Epoch [5/5], Step [14/1200], Loss: 0.1967\n",
            "Epoch [5/5], Step [15/1200], Loss: 0.0923\n",
            "Epoch [5/5], Step [16/1200], Loss: 0.1146\n",
            "Epoch [5/5], Step [17/1200], Loss: 0.1975\n",
            "Epoch [5/5], Step [18/1200], Loss: 0.1472\n",
            "Epoch [5/5], Step [19/1200], Loss: 0.0192\n",
            "Epoch [5/5], Step [20/1200], Loss: 0.0683\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "u5C9JEj90qYT",
        "colab_type": "code",
        "outputId": "f1c7c56e-8152-4440-bc39-886f9dbb28bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Test the model on MNIST dataset\n",
        "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Test Accuracy of 1000 images trained model on the MNIST fulltestset: {} %'.format(100 * correct / total))\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy of 1000 images trained model on the MNIST fulltestset: 96.81 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "s_qIN9XG2yzi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Discussion and plot"
      ]
    },
    {
      "metadata": {
        "id": "OdurHY95251T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### The accuracy achieved on the full test MNIST dataset for each trained model is:\n"
      ]
    },
    {
      "metadata": {
        "id": "MbJIQqbwUMYG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Test Accuracy of 100 images trained model on the MNIST fulltestset: 96.96 %\n",
        "\n",
        "Test Accuracy of 250 images trained model on the MNIST fulltestset: 97.34 %\n",
        "\n",
        "Test Accuracy of 500 images trained model on the MNIST fulltestset: 96.37 %\n",
        "\n",
        "Test Accuracy of 1000 images trained model on the MNIST fulltestset: 95.08 %\n",
        "\n",
        "Test Accuracy of 60000 images trained model on the MNIST fulltestset:  99.16 %\n",
        "\n",
        "In conclusion, In a large range, as the increase of the trainning dataset, the test accuracy increases."
      ]
    },
    {
      "metadata": {
        "id": "GdWHimbyUuJM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### The accuracy of trainning"
      ]
    },
    {
      "metadata": {
        "id": "NUDRwD4VU5Ss",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Trainning Accuracy of 100 images trained model : (1- 0.2683) * 100% = 73.17%\n",
        "\n",
        "Trainning Accuracy of 250 images trained model: (1- 0.2405) * 100% = 75.95% \n",
        "\n",
        "Trainning Accuracy of 500 images trained model: (1- 0.1797) * 100% = 82.03%\n",
        "\n",
        "Trainning Accuracy of 1000 images trained model: (1- 0.0683) * 100% = 93.17%\n",
        "\n",
        "Trainning Accuracy of 60000 images trained model : (1- 0.0007) * 100% = 99.93%\n",
        "\n",
        "In conclusion, In a large range, as the increase of the trainning dataset, the train accuracy increases."
      ]
    },
    {
      "metadata": {
        "id": "V_TK-o203vVV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### The learning curve"
      ]
    },
    {
      "metadata": {
        "id": "OnsVRPwQ4DAA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "outputId": "53375707-b9cd-4d2c-8000-7371d08a89c3"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "trainSet = [100, 250, 500, 1000, 60000]\n",
        "testAccuracy = [0.9696, 0.9734, 0.9637, 0.9508, 0.9916]\n",
        "trainAccuracy = [0.7317, 0.7595, 0.8203, 0.9317, 0.9993]\n",
        "x = np.arange(1,6)\n",
        "#plt.ylim(0.7, 1)\n",
        "#plt.xlim(0,1200, 60000 )\n",
        "plt.figure(1)\n",
        "plt.title('Learning curve for CNN model in tutorial')\n",
        "#plt.axis([100, 250, 500, 1000, 60000])\n",
        "plt.plot( x, testAccuracy, marker='o')\n",
        "plt.plot( x, trainAccuracy, marker='*')\n",
        "plt.xlabel('Size of trainning dataset: 100, 250, 500, 1000, 60000')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No handles with labels found to put in legend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFnCAYAAAC/5tBZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f9ad931e6a0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "sFanpPsR2mDC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Discussion"
      ]
    },
    {
      "metadata": {
        "id": "sLrgKhxGcuRI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Because the range of my train dataset is so large, it range from 100 to 60000, and there is no train dataset between 1200-59000, so to make the dot distribute more clear in my line graph, I change the X axis, the correct X value of every dot  is in the legend of X axis.   \n",
        "\n",
        "In conclusion, In a large range, as the increase of the trainning dataset, both the test accuracy and the train accuracy increases.\n",
        "\n",
        "why did the test accuracy is not absolute linear increased by the size of trainning dataset. Because I set the epoch = 1 to speed up trainning process, which make the performance of every model fluctuate much during every time I train and test.\n",
        "If I increase the epoch to let it iterate more during the trainning process, the performance will be more stable."
      ]
    },
    {
      "metadata": {
        "id": "13MwZLXl2HaZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##  2. Pytorch system evaluation"
      ]
    },
    {
      "metadata": {
        "id": "zQsp77aJ2OdX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Select the best and worst performing of the trained models in part 1. For each of these models test with both the training set and my own test set.\n",
        "\n",
        "The code of testing on my dataset is in another notebook because of some tricky issue of loading my own dataset and make dataloader,\n",
        "the code of experiemnt in MNIST dataset are in part 1.\n",
        "So in this part, we just discuss the test accuracy of the two models."
      ]
    },
    {
      "metadata": {
        "id": "7uZ7aRyl-Ugr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.1 The best performing of the trained models is the 60000 images trained model.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "gNvrLpXQMwPG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For this model: \n",
        "\n",
        "the test accuracy on MNIST dataset is : 99.16 %\n",
        "\n",
        "the test accuracy on my dataset is: 73.33333333333333 %\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Z6N6vJTOMzd1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.2 The worse performing of the trained models is the 100 images trained model.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "eSKhS6htM3pX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For this model:\n",
        "\n",
        "the test accuracy on MNIST dataset is : 96.96 %\n",
        "\n",
        "the test accuracy on my dataset is: 66.66666666666667 %\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "L4iUhLMkM6G0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.3 The accuracy of other models on mydataset:\n"
      ]
    },
    {
      "metadata": {
        "id": "iDPyxTVnQrLi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "Test Accuracy of 100 images trained model on the my dataset: 66.66666666666667 %\n",
        "\n",
        "Test Accuracy of 250 images trained model on the my dataset: 68.33333333333333 %\n",
        "\n",
        "Test Accuracy of 500 images trained model on the my dataset: 70.0 %\n",
        "\n",
        "Test Accuracy of 1000 images trained model on the my dataset: 68.33333333333333 %\n",
        "\n",
        "Test Accuracy of 60000 images trained model on the my dataset: 73.33333333333333 %\n"
      ]
    },
    {
      "metadata": {
        "id": "jhZPgC5DgNBT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.4 learning curve for my testset and discussion"
      ]
    },
    {
      "metadata": {
        "id": "Gap50HT7etcM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "a8381200-4d71-46cf-c908-cd8970b54514"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "trainSet = [100, 250, 500, 1000, 60000]\n",
        "mytestAccuracy = [0.6667, 0.6833, 0.70, 0.6833, 0.7333]\n",
        "\n",
        "plt.ylim(0.6, 0.8)\n",
        "#plt.xlim(0,1200, 60000 )\n",
        "plt.figure(1)\n",
        "plt.title('Learning curve for CNN model tested on my dataset in tutorial')\n",
        "plt.plot(trainSet, mytestAccuracy, marker='o', label='Test accuracy on my data')\n",
        "plt.xlabel('Size of trainning dataset')\n",
        "plt.ylabel('Test accuracy on my data')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfsAAAFnCAYAAAChL+DqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIhanshcREbE4lb2IiIjFqexFREQs7r/T9pMgX/YbcgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f9aed5c9ac8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Arl3bY6Mf1xj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In conclusion, In a large range, as the increase of the trainning dataset, both the test accuracy on my data set and on MNIST dataset increases."
      ]
    },
    {
      "metadata": {
        "id": "L8spUaVD-OwC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3. Keras model design\n"
      ]
    },
    {
      "metadata": {
        "id": "ynknFota-TZm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We explore different model designs using the Keras framework."
      ]
    },
    {
      "metadata": {
        "id": "kRgGjytKNDJz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Prepare the 1st model in tutorial"
      ]
    },
    {
      "metadata": {
        "id": "usURR9VF-SHU",
        "colab_type": "code",
        "outputId": "307d8ce5-d638-47bf-b5aa-99a13a874e6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "'''Trains a simple convnet on the MNIST dataset.\n",
        "Gets to 99.25% test accuracy after 12 epochs\n",
        "(there is still a lot of margin for parameter tuning).\n",
        "16 seconds per epoch on a GRID K520 GPU.\n",
        "'''\n",
        "\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 1\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7KqZgw9VcoRH",
        "colab_type": "code",
        "outputId": "9efcf931-f4ce-4731-8aba-3d8983e2f9bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "cell_type": "code",
      "source": [
        "#build 1st model according to tutorial\n",
        "model = Sequential()\n",
        "#add layer\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss for model in tutorial:', score[0])\n",
        "print('Test accuracy for model in tutorial:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "60000/60000 [==============================] - 171s 3ms/step - loss: 0.2638 - acc: 0.9192 - val_loss: 0.0592 - val_acc: 0.9796\n",
            "Test loss for model in tutorial: 0.05922309949898626\n",
            "Test accuracy for model in tutorial: 0.9796\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i3wZjtGcE264",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3.1 Show a confusion matrix for the result of the model in the tutorial."
      ]
    },
    {
      "metadata": {
        "id": "h27D84QOLCkg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 3.1.1 Show the unnormalized confusion matrix for the result of the model in the tutorial."
      ]
    },
    {
      "metadata": {
        "id": "-BRKUSgNCPC8",
        "colab_type": "code",
        "outputId": "5b606913-5559-4fbe-a8ad-67be030fb12f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "Y_pred = model.predict(x_test)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "Y_test = np.argmax(y_test, axis=1)\n",
        "\n",
        "print(\"y_predicted_values\", y_pred)\n",
        "print(\"Y_test_values\", Y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y_predicted_values [7 2 1 ... 4 5 6]\n",
            "Y_test_values [7 2 1 ... 4 5 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "slM9gZXmF_Rm",
        "colab_type": "code",
        "outputId": "ab1dbf51-c4dd-4cbe-8a91-7b4db5a51582",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "#import matplotlib.pyplot as plt \n",
        "cfm = confusion_matrix(Y_test, y_pred)\n",
        "print (cfm)\n",
        "\n",
        "#plt.imshow(cfm)\n",
        "#plt.title('My title')\n",
        "#plt.xlabel('categories')\n",
        "#plt.ylabel('values')\n",
        "#plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 975    0    1    0    0    1    2    1    0    0]\n",
            " [   0 1130    1    2    0    0    1    0    1    0]\n",
            " [   2    3 1019    1    1    0    0    6    0    0]\n",
            " [   0    0    3  994    0    5    0    5    2    1]\n",
            " [   0    0    2    0  964    0    4    0    2   10]\n",
            " [   1    0    1    5    0  880    2    1    1    1]\n",
            " [   8    3    0    0    4    5  938    0    0    0]\n",
            " [   1    3   14    2    0    0    0 1001    2    5]\n",
            " [   6    1    6    2    4    4    2    4  940    5]\n",
            " [   3    5    0    3    5    5    0    5    3  980]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mrYQzIySK7j8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 3.1.2 Show normalized confusion matrix for the result of the model in the tutorial."
      ]
    },
    {
      "metadata": {
        "id": "o0gTS6RhJNdy",
        "colab_type": "code",
        "outputId": "be42cd45-a019-47d2-ae09-35dd25a49467",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "cell_type": "code",
      "source": [
        "## A more elegant preserntation for a confusion matrix\n",
        "\n",
        "import itertools\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    #print(cm)\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "        \n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    #plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_confusion_matrix(cfm, classes=range(10), normalize=True,\n",
        "                      title='Confusion matrix for MNIST')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normalized confusion matrix\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAFoCAYAAABAGRzjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f705ad59e10>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "OVCTQ1SqNOjv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3.2 CNN model with batch normalization and image standardization "
      ]
    },
    {
      "metadata": {
        "id": "kcLC8uUrTedJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 3.2.1 only batch normalization"
      ]
    },
    {
      "metadata": {
        "id": "t8fs1WSMdLtM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### add one batch norm layer"
      ]
    },
    {
      "metadata": {
        "id": "OIIkRdZMNZ3H",
        "colab_type": "code",
        "outputId": "2153f8ee-448e-4182-c4f4-9065bddd6c7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "#build model2 with batch norm \n",
        "model2 = Sequential()\n",
        "#add layer\n",
        "\n",
        "model2.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "\n",
        "# add batch norm layer\n",
        "model2.add(keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None))\n",
        "\n",
        "model2.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Dropout(0.25))\n",
        "model2.add(Flatten())\n",
        "model2.add(Dense(128, activation='relu'))\n",
        "model2.add(Dropout(0.5))\n",
        "model2.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model2.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model2.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "score = model2.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss for model in tutorial with batch norm:', score[0])\n",
        "print('Test accuracy for model in tutorial with batch norm::', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "60000/60000 [==============================] - 227s 4ms/step - loss: 0.3143 - acc: 0.9051 - val_loss: 0.0534 - val_acc: 0.9822\n",
            "Test loss for model in tutorial with batch norm: 0.05342521703434177\n",
            "Test accuracy for model in tutorial with batch norm:: 0.9822\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yM9Lgi21dUg1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### add two batch norm layer"
      ]
    },
    {
      "metadata": {
        "id": "JeNZXb8Mdap5",
        "colab_type": "code",
        "outputId": "6ba9e5ab-c126-4611-c0a9-6c9bae4a1fab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "cell_type": "code",
      "source": [
        "#build model22 with 2 batch norm layer\n",
        "model22 = Sequential()\n",
        "#add layer\n",
        "\n",
        "model22.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "\n",
        "# add batch norm layer\n",
        "model22.add(keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None))\n",
        "\n",
        "model22.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model22.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model22.add(Dropout(0.25))\n",
        "model22.add(Flatten())\n",
        "model22.add(Dense(128, activation='relu'))\n",
        "model22.add(Dropout(0.5))\n",
        "\n",
        "# add batch norm layer\n",
        "model22.add(keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None))\n",
        "\n",
        "model22.add(Dense(num_classes, activation='softmax'))\n",
        "model22.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model22.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "score = model22.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss for model in tutorial with 2 batch norm layers:', score[0])\n",
        "print('Test accuracy for model in tutorial with 2 batch norm layers:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "60000/60000 [==============================] - 228s 4ms/step - loss: 0.1996 - acc: 0.9459 - val_loss: 0.0569 - val_acc: 0.9837\n",
            "Test loss for model in tutorial with 2 batch norm layers: 0.05689856858402491\n",
            "Test accuracy for model in tutorial with 2 batch norm layers: 0.9837\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "U0m3hO4KTjcA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 3.2.2 only image standarlization"
      ]
    },
    {
      "metadata": {
        "id": "P6tuzmj_Tq5D",
        "colab_type": "code",
        "outputId": "87e98da9-da16-4dc2-efa0-52e41b893a4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1005
        }
      },
      "cell_type": "code",
      "source": [
        "#build model3 according to tutorial\n",
        "\n",
        "#from sklearn import preprocessing\n",
        "#from sklearn.preprocessing import StandardScaler  \n",
        "#x_train2d = x_train.reshape(x_train.shape[0], 784)\n",
        "#x_test2d = x_test.reshape(x_test.shape[0], 784)\n",
        "#scaler = StandardScaler()  \n",
        "# fit only on training data\n",
        "#scaled_x_train = scaler.fit_transform(x_train2d) / 255\n",
        "# apply same transformation to test data\n",
        "#scaled_x_test = scaler.transform(x_test2d) / 255\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "#standardlize\n",
        "testmean= np.mean(x_test)\n",
        "teststd= np.std(x_test, axis = 0)\n",
        "scaled_x_test = (x_test - testmean) / teststd\n",
        "\n",
        "trainmean= np.mean(x_train)\n",
        "trainstd= np.std(x_test, axis = 0)\n",
        "scaled_x_train = (x_train - trainmean) / trainstd\n",
        "\n",
        "#build model with image standarlization\n",
        "model3 = Sequential()\n",
        "#add layer\n",
        "\n",
        "model3.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "model3.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model3.add(Dropout(0.25))\n",
        "model3.add(Flatten())\n",
        "model3.add(Dense(128, activation='relu'))\n",
        "model3.add(Dropout(0.5))\n",
        "model3.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model3.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model3.fit(scaled_x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(scaled_x_test, y_test))\n",
        "\n",
        "score = model3.evaluate(scaled_x_test, y_test, verbose=0)\n",
        "print('Test loss for model in tutorial with image standardlization:', score[0])\n",
        "print('Test accuracy for model in tutorial with image standardlization:', score[1])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "60000/60000 [==============================] - 167s 3ms/step - loss: nan - acc: 0.0987 - val_loss: nan - val_acc: 0.0980\n",
            "Test loss for model in tutorial with image standardlization: nan\n",
            "Test accuracy for model in tutorial with image standardlization: 0.098\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mtdmH32cB1up",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Why dose my loss shows NAN:\n",
        "\n",
        "Because I choosed a not proper batch size, the batch size I choose equals to Its minimum, which is 1, resulting in stochastic gradient descent: Fast but the direction of the gradient step is based only on one example, the loss may jump around."
      ]
    },
    {
      "metadata": {
        "id": "B49pQpQAc_f2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 3.2.2 use both image standarlization and batch normalization"
      ]
    },
    {
      "metadata": {
        "id": "rHhO0OPZdFw4",
        "colab_type": "code",
        "outputId": "b2c7d92b-b9eb-4ba6-f0da-08d5db97bd83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1005
        }
      },
      "cell_type": "code",
      "source": [
        "#build model4 according to tutorial\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "#standardlize\n",
        "testmean= np.mean(x_test)\n",
        "teststd= np.std(x_test, axis = 0)\n",
        "scaled_x_test = (x_test - testmean) / teststd\n",
        "\n",
        "trainmean= np.mean(x_train)\n",
        "trainstd= np.std(x_test, axis = 0)\n",
        "scaled_x_train = (x_train - trainmean) / trainstd\n",
        "\n",
        "\n",
        "#build model with image standarlization\n",
        "model4 = Sequential()\n",
        "#add layer\n",
        "\n",
        "model4.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "\n",
        "# add batch norm layer\n",
        "model4.add(keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None))\n",
        "\n",
        "\n",
        "model4.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model4.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model4.add(Dropout(0.25))\n",
        "model4.add(Flatten())\n",
        "model4.add(Dense(128, activation='relu'))\n",
        "model4.add(Dropout(0.5))\n",
        "model4.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model4.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model4.fit(scaled_x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(scaled_x_test, y_test))\n",
        "\n",
        "score = model4.evaluate(scaled_x_test, y_test, verbose=0)\n",
        "print('Test loss for model in tutorial with image standardlization and batch norm:', score[0])\n",
        "print('Test accuracy for model in tutorial with image standardlization and batch norm:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "60000/60000 [==============================] - 227s 4ms/step - loss: nan - acc: 0.0987 - val_loss: nan - val_acc: 0.0980\n",
            "Test loss for model in tutorial with image standardlization and batch norm: nan\n",
            "Test accuracy for model in tutorial with image standardlization and batch norm: 0.098\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XkGKIJhA5W37",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Discussion"
      ]
    },
    {
      "metadata": {
        "id": "HvsSLvkh3yy3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We use the test accuracy as the metrix to evaluate the performance of the model we build. \n",
        "\n",
        "We find that to increase the performance, the batch norm layer is better to add between conv layers or near the output layer, but before the dense layer.\n",
        "Through my experiment on adding different numbers of batch norm layer, I find my model with 2 batch norm layer will be better than my model with only one batch norm layer. And the first batch norm layer I add between the two conv layer, the second I add before the last dense layer near the output layer.\n",
        "\n",
        "Main parameters of my batch norm layer is: axis=-1, momentum=0.99, epsilon=0.001\n",
        "\n",
        "Sometimes batch norm layer will destroy the model, especially when we do batch norm before the first conv layer or in the output layer.\n",
        "\n",
        "For the **reason**, we can think that the batch norm will be some kind of adaptive (or learnable) pre-processing block with trainable parameters. Which also means that we need to back-propagate them.\n",
        "\n",
        "Here is the list of advantages of using Batch-Norm:\n",
        "\n",
        "1. Improves gradient flow, used on very deep models (Resnet need this)\n",
        "2. Allow higher learning rates\n",
        "3. Reduce dependency on initialization\n",
        "4. Gives some kind of regularization (Even make Dropout less important but keep using it)\n",
        "5. As a rule of thumb if you use Dropout+BatchNorm you don't need L2 regularization\n",
        "\n",
        "For standarlization: \n",
        "A strange value is my loss, which is NAN, I think it probabily because I choosed a not proper batch size, or my epoch is so low that only equals 1, so the loss may jump around."
      ]
    },
    {
      "metadata": {
        "id": "4drIecTQeZn2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3.3 CNN model with a new convolution layer to the model in the tutorial"
      ]
    },
    {
      "metadata": {
        "id": "ohswQT2iefes",
        "colab_type": "code",
        "outputId": "5005423f-f9e3-4c48-dbee-ae5eefb29648",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "cell_type": "code",
      "source": [
        "#build model5 according to tutorial\n",
        "\n",
        "model5 = Sequential()\n",
        "#add layer\n",
        "model5.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model5.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model5.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# add conv layer and pooling layer\n",
        "model5.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model5.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model5.add(Dropout(0.25))\n",
        "model5.add(Flatten())\n",
        "model5.add(Dense(128, activation='relu'))\n",
        "model5.add(Dropout(0.5))\n",
        "model5.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model5.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model5.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "score = model5.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss for model I add a new conv layer and pool layer:', score[0])\n",
        "print('Test accuracy for model I add a new conv layer and pool layer:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "60000/60000 [==============================] - 185s 3ms/step - loss: 0.2751 - acc: 0.9123 - val_loss: 0.0513 - val_acc: 0.9839\n",
            "Test loss for model in tutorial: 0.051303200916352217\n",
            "Test accuracy for model in tutorial: 0.9839\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xCPPgahE3v4o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Discussion"
      ]
    },
    {
      "metadata": {
        "id": "5ji-6UwUxPVm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " We add another convolutional + max pooling layer, with 64 output channels.  The default strides argument in the Conv2D() function is (1, 1) in Keras, so we can leave it out.  The default strides argument in Keras is to make it equal ot the pool size, so again, we can leave it out.\n",
        " \n",
        " This model contains 10 layers: a conv layer with 3X3 kernal; a conv layer with 3X3 kernal; a pooling layer; a conv layer with 3X3 kernal; a pooling layer; a Dropout(0.25) layer; a flatten layer; a dense(128) layer; a dropout(0.5) layer; a dense layer. \n",
        "\n",
        "Test accuracy for this model is : 0.9839\n",
        "Train accuracy for this model is : 0.4870"
      ]
    },
    {
      "metadata": {
        "id": "3_mf-OiiyQTr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3.4  Modify the model to improve performance"
      ]
    },
    {
      "metadata": {
        "id": "8Oe0Uj6QyWje",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " Modify the model in any way  and see how much you can improve the performance. Include a table in this report which list which hyperparameter settings you explored and the associated performance. Show a confusion matrix for your best trained model."
      ]
    },
    {
      "metadata": {
        "id": "8PP-GMwc01xU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### model6 with a new conv layer with 3X3 kernal, and a pooling layer, also two batch norm layers."
      ]
    },
    {
      "metadata": {
        "id": "EH2fPcs0ynAj",
        "colab_type": "code",
        "outputId": "b71bc7f6-7e9b-4746-c191-abe1895580ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "#build model6 according to tutorial\n",
        "\n",
        "model6 = Sequential()\n",
        "#add layer\n",
        "model6.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "\n",
        "# add batch norm layer\n",
        "model6.add(keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None))\n",
        "\n",
        "model6.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model6.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# add conv layer and pooling layer\n",
        "model6.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model6.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model6.add(Dropout(0.25))\n",
        "model6.add(Flatten())\n",
        "model6.add(Dense(128, activation='relu'))\n",
        "model6.add(Dropout(0.5))\n",
        "\n",
        "# add batch norm layer\n",
        "model6.add(keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None))\n",
        "\n",
        "\n",
        "model6.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model6.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model6.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "score = model6.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss for mymodel6:', score[0])\n",
        "print('Test accuracy for mymodel6:', score[1])"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "60000/60000 [==============================] - 254s 4ms/step - loss: 0.2328 - acc: 0.9341 - val_loss: 0.0458 - val_acc: 0.9855\n",
            "Test loss for mymodel6: 0.045837517319526525\n",
            "Test accuracy for mymodel6: 0.9855\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TFr3mNTCjt1q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This model contains 12 layers: a conv layer with 3X3 kernal; a batch norm layer; a conv layer with 3X3 kernal; a pooling layer;  a conv layer with 3X3 kernal; a pooling layer; a Dropout(0.25) layer; a flatten layer; a dense(128) layer; a dropout(0.5) layer; a batch norm layer; a dense layer. \n",
        "\n",
        "Test accuracy for this model is : 0.9855\n",
        "\n",
        "Train accuracy for this model is : 0.9542"
      ]
    },
    {
      "metadata": {
        "id": "waM6jXyH1TCE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### model7: revise kernal as 5X5"
      ]
    },
    {
      "metadata": {
        "id": "litGRLUV1b9i",
        "colab_type": "code",
        "outputId": "28679df2-9b1d-4f06-dfd5-8e006186dd4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "cell_type": "code",
      "source": [
        "#build model7 according to tutorial\n",
        "\n",
        "model7 = Sequential()\n",
        "#add layer\n",
        "model7.add(Conv2D(32, kernel_size=(5, 5),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "\n",
        "# add batch norm layer\n",
        "model7.add(keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None))\n",
        "\n",
        "model7.add(Conv2D(64, (5, 5), activation='relu'))\n",
        "model7.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# add conv layer and pooling layer\n",
        "model7.add(Conv2D(64, (5, 5), activation='relu'))\n",
        "model7.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model7.add(Dropout(0.25))\n",
        "model7.add(Flatten())\n",
        "model7.add(Dense(128, activation='relu'))\n",
        "model7.add(Dropout(0.5))\n",
        "\n",
        "# add batch norm layer\n",
        "model7.add(keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None))\n",
        "\n",
        "\n",
        "model7.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model7.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model7.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "score = model7.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss for mymodel7:', score[0])\n",
        "print('Test accuracy for mymodel7:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "60000/60000 [==============================] - 338s 6ms/step - loss: 0.2866 - acc: 0.9180 - val_loss: 0.0673 - val_acc: 0.9794\n",
            "Test loss for mymodel6: 0.06725342419473454\n",
            "Test accuracy for mymodel6: 0.9794\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pVTUfTMWmMei",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This model contains 12 layers: a conv layer with 5X5 kernal; a batch norm layer; a conv layer with 5X5 kernal; a pooling layer;  a conv layer with 3X3 kernal; a pooling layer; a Dropout(0.25) layer; a flatten layer; a dense(128) layer; a dropout(0.5) layer; a batch norm layer; a dense layer. \n",
        "\n",
        "Test accuracy for this model is : 0.9794\n",
        "\n",
        "Train accuracy for this model is : 0.9327"
      ]
    },
    {
      "metadata": {
        "id": "AWa8E9MV2B2f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### model8: revise dense layer, set dense as 1000"
      ]
    },
    {
      "metadata": {
        "id": "xRitopec2IiE",
        "colab_type": "code",
        "outputId": "1b0f570c-bc94-4b57-daae-ce526df9eaa1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "cell_type": "code",
      "source": [
        "#build model8 according to tutorial\n",
        "\n",
        "model8 = Sequential()\n",
        "#add layer\n",
        "model8.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "\n",
        "# add batch norm layer\n",
        "model8.add(keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None))\n",
        "\n",
        "model8.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model8.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# add conv layer and pooling layer\n",
        "model8.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model8.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model8.add(Dropout(0.25))\n",
        "model8.add(Flatten())\n",
        "model8.add(Dense(1000, activation='relu'))\n",
        "model8.add(Dropout(0.5))\n",
        "\n",
        "# add batch norm layer\n",
        "model8.add(keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None))\n",
        "\n",
        "\n",
        "model8.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model8.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model8.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "score = model8.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss for mymodel8:', score[0])\n",
        "print('Test accuracy for mymodel8:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "60000/60000 [==============================] - 281s 5ms/step - loss: 0.1343 - acc: 0.9586 - val_loss: 0.0519 - val_acc: 0.9837\n",
            "Test loss for mymodel6: 0.051948512578918596\n",
            "Test accuracy for mymodel6: 0.9837\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CQkBcifmm5hO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This model contains 12 layers: a conv layer with 3X3 kernal; a batch norm layer; a conv layer with 3X3 kernal; a pooling layer;  a conv layer with 3X3 kernal; a pooling layer; a Dropout(0.25) layer; a flatten layer; a dense(1000) layer; a dropout(0.5) layer; a batch norm layer; a dense layer. \n",
        "\n",
        "Test accuracy for this model is : 0.9837\n",
        "Train accuracy for this model is : 0.9481"
      ]
    },
    {
      "metadata": {
        "id": "PlVboYdO8BGP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### model9 change dense = 5"
      ]
    },
    {
      "metadata": {
        "id": "aXaN8ryN8YYY",
        "colab_type": "code",
        "outputId": "b9830f6d-f9d1-4ffe-8922-dd9bbc898938",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "cell_type": "code",
      "source": [
        "#build model9 according to tutorial\n",
        "\n",
        "model9 = Sequential()\n",
        "#add layer\n",
        "model9.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "\n",
        "# add batch norm layer\n",
        "model9.add(keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None))\n",
        "\n",
        "model9.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model9.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# add conv layer and pooling layer\n",
        "model9.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model9.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model9.add(Dropout(0.25))\n",
        "model9.add(Flatten())\n",
        "model9.add(Dense(5, activation='relu'))\n",
        "model9.add(Dropout(0.5))\n",
        "\n",
        "# add batch norm layer\n",
        "model9.add(keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None))\n",
        "\n",
        "\n",
        "model9.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model9.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model9.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "score = model9.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss for mymodel9:', score[0])\n",
        "print('Test accuracy for mymodel9:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "60000/60000 [==============================] - 256s 4ms/step - loss: 1.7585 - acc: 0.3550 - val_loss: 1.0611 - val_acc: 0.8668\n",
            "Test loss for mymodel9: 1.0610666137695313\n",
            "Test accuracy for mymodel9: 0.8668\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AT7sTH2dnIos",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This model contains 12 layers: a conv layer with 3X3 kernal; a batch norm layer; a conv layer with 3X3 kernal; a pooling layer;  a conv layer with 3X3 kernal; a pooling layer; a Dropout(0.25) layer; a flatten layer; a dense(5) layer; a dropout(0.5) layer; a batch norm layer; a dense layer. \n",
        "\n",
        "Test accuracy for this model is : 0.8668\n"
      ]
    },
    {
      "metadata": {
        "id": "ACu2zUXt8QWB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### model10 change dense = 64"
      ]
    },
    {
      "metadata": {
        "id": "wokfmf7_9ztF",
        "colab_type": "code",
        "outputId": "81795d0d-816c-4d7d-eea2-1139ca3bb26f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "cell_type": "code",
      "source": [
        "#build model0 according to tutorial\n",
        "\n",
        "model0 = Sequential()\n",
        "#add layer\n",
        "model0.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "\n",
        "# add batch norm layer\n",
        "model0.add(keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None))\n",
        "\n",
        "model0.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model0.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# add conv layer and pooling layer\n",
        "model0.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model0.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model0.add(Dropout(0.25))\n",
        "model0.add(Flatten())\n",
        "model0.add(Dense(64, activation='relu'))\n",
        "model0.add(Dropout(0.5))\n",
        "\n",
        "# add batch norm layer\n",
        "model0.add(keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None))\n",
        "\n",
        "\n",
        "model0.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model0.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model0.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "score = model0.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss for mymodel0:', score[0])\n",
        "print('Test accuracy for mymodel0:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "60000/60000 [==============================] - 261s 4ms/step - loss: 0.6410 - acc: 0.8219 - val_loss: 0.0699 - val_acc: 0.9819\n",
            "Test loss for mymodel0: 0.06985671087801457\n",
            "Test accuracy for mymodel0: 0.9819\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mBk9GigAnZOz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This model contains 12 layers: a conv layer with 3X3 kernal; a batch norm layer; a conv layer with 3X3 kernal; a pooling layer;  a conv layer with 3X3 kernal; a pooling layer; a Dropout(0.25) layer; a flatten layer; a dense(64) layer; a dropout(0.5) layer; a batch norm layer; a dense layer. \n",
        "\n",
        "Test accuracy for this model is : 0.9819\n",
        "\n",
        "Train accuracy for this model is : 0.9302"
      ]
    },
    {
      "metadata": {
        "id": "u1DPR1w78wJD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### model11 change third conv2d = 128"
      ]
    },
    {
      "metadata": {
        "id": "9DmyCKwU_OX-",
        "colab_type": "code",
        "outputId": "87159c1b-8fba-46eb-8646-71b1e277e108",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "cell_type": "code",
      "source": [
        "#build model11 according to tutorial\n",
        "\n",
        "model11 = Sequential()\n",
        "#add layer\n",
        "model11.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "\n",
        "# add batch norm layer\n",
        "model11.add(keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None))\n",
        "\n",
        "model11.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model11.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# add conv layer and pooling layer\n",
        "model11.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model11.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model11.add(Dropout(0.25))\n",
        "model11.add(Flatten())\n",
        "model11.add(Dense(5, activation='relu'))\n",
        "model11.add(Dropout(0.5))\n",
        "\n",
        "# add batch norm layer\n",
        "model11.add(keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None))\n",
        "\n",
        "\n",
        "model11.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model11.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model11.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "score = model11.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss for mymodel11:', score[0])\n",
        "print('Test accuracy for mymodel11:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "60000/60000 [==============================] - 294s 5ms/step - loss: 1.7756 - acc: 0.3326 - val_loss: 0.8206 - val_acc: 0.8767\n",
            "Test loss for mymodel11: 0.8206356763839722\n",
            "Test accuracy for mymodel11: 0.8767\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hwGerUiNo-Vt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This model contains 12 layers: a conv layer with 3X3 kernal; a batch norm layer; a conv layer with 3X3 kernal; a pooling layer; a conv layer with 3X3 kernal; a pooling layer; a Dropout(0.25) layer; a flatten layer; a dense(128) layer; a dropout(0.5) layer; a batch norm layer; a dense layer. \n",
        "\n",
        "Test accuracy for this model is : 0.8206"
      ]
    },
    {
      "metadata": {
        "id": "mDbHLzWahUn1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Table of my hyperparameter settings and the associated performance"
      ]
    },
    {
      "metadata": {
        "id": "VZhd5aOVhdxv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "All these models are trained with 60000 train samples in MNIST dataset, \n",
        "and tested with 10000 test samples in MNIST dataset."
      ]
    },
    {
      "metadata": {
        "id": "XwDwfiopriP_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " batch_size = 128; num_classes = 10; epochs = 1\n",
        "\n",
        "\n",
        "| layer composition and hyperparameter      |        |        |     |   |\n",
        "|------------------------------------------|-------:|-------:|----:|--:|\n",
        "| conv(32, kernel 3X3)                     |    3X3   |    3X3   | 5X5 |  3X3 | 3X3|3X3|3X3|3X3|\n",
        "| batch norm(momentum=0.99, epsilon=0.001) |    ✓   |   ✘     |  ✓   | ✓  | ✓|✓|✓| ✓|\n",
        "| conv(64, kernel 3X3)                     | ✓      | ✓      | ✓    | ✓  |✓|✓|✓|✓|\n",
        "| pooling(2X2)                            | ✓      |    ✓   |   ✓  |  ✓ |✓|✓|✓|✓|\n",
        "| conv(64, kernel 3X3)                     |    3X3   | 3X3      | 5X5     |  3X3 |3X3|3X3|3X3|✘ |\n",
        "| pooling(2X2)                            |    ✓   |    ✓   |  ✓   | ✓  |✓|✓|✓|✘ |\n",
        "| dropout(0.25)                            |    ✓   |    ✓   | ✓    | ✓  |✓|✓|✓|✓|\n",
        "| flatten                                  |    ✓   |    ✓   |  ✓   | ✓  |✓|✓|✓|✓|\n",
        "| dense(128)                               |    128   |    128   |  128   | 1000  |5|64|11|128|\n",
        "| dropout(0.5)                             |    ✓   |    ✓   |  ✓   |  ✓ |✓|✓|✓|✓|\n",
        "| batch norm(momentum=0.99, epsilon=0.001) |    ✓   |   ✘     |  ✓   | ✓  |✓|✓|✓|✘ |\n",
        "| dense                                    |    ✓   |    ✓   |  ✓   |  ✓ |✓|✓|✓|✓|\n",
        "|    Test Accuracy on MNIST 1000testset    | 0.9855 | 0.9839 |    0.9794 | 0.9837  |0.8668|0.9819|0.8266|0.9822|\n"
      ]
    },
    {
      "metadata": {
        "id": "siOrXEqj3H_5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We use the test accuracy as the metrix to evaluate the performance of the model we build with the change of hyperparameter. \n",
        "\n",
        "We find that batch norm layer is better to add between conv layers or near the output layer, but before the dense layer, and properly add batch norm layer will increase the performance. Model with two batch norm layers will performs batter than model with one batch norm layer.\n",
        "\n",
        "Then, for the kernal size in conv layer, 3X3 is enough for this classification experiment on MNIST dataset. 5X5 is so large that decreased the performance.\n",
        "The kernel size generally refers to the widthxheight of the filter mask. The max pooling layer, for example, returns the pixel with maximum value from a set of pixels within a mask (kernel). Very small kernal sizes will capture very fine details of the image. On the other hand having a bigger kernal size will leave out minute details in the image.\n",
        "\n",
        "For dense layer: 128 is quite good, we have tried 5, 11, 64, 1000, we find slightly increase th dense  or make the dense really big, such as 1000, which won't make a big difference on the performance, but if the dense is so low, it decrease the performance severely. A dense layer we can understand it as a  regular layer of neurons in a neural network.\n",
        "\n",
        "For pooling layer: 2X2 is good for this experiment.\n",
        "Pooling layer It is also referred to as a downsampling layer. In this category, there are also several layer options, with maxpooling being the most popular. This basically takes a filter (normally of size 2x2) and a stride of the same length. It then applies it to the input volume and outputs the maximum number in every subregion that the filter convolves around.\n",
        "\n",
        "For dropout layer: I have two drop out layers in my model, both of them are after the conv and pooling layer, one dropout value is 0.25, another is 0.5, which are good choices. Dropout is a a technique used to tackle Overfitting . The Dropout method in keras.layers module takes in a float between 0 and 1, which is the fraction of the neurons to drop.\n",
        "\n",
        "For batch size: My choice of 128 is a good guess. Both give us a not bad loss and a reasonalble tranning speed. Batch size determines the number of samples in each mini batch.\n",
        "\n",
        "For epoch: My choice of 1 is not a good guess. I choose 1 only because of the trainning speed is so slow. \n"
      ]
    },
    {
      "metadata": {
        "id": "N_B3uXbuhA2d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Confusion matrix for my best model"
      ]
    },
    {
      "metadata": {
        "id": "2j6np6xYjbbt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "My best model is model6, I add a batch norm layer with (momentum=0.99, epsilon=0.001) after the 1st conv layer, then  I add a new conv layer with Conv2D(64, (3, 3 )and pooling layer with pool size (2,2) after the batch layer, "
      ]
    },
    {
      "metadata": {
        "id": "CTO-cwNvjaYQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "da262bea-3a60-487a-9745-587a85a0e9e6"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "Y_pred = model6.predict(x_test)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "Y_test = np.argmax(y_test, axis=1)\n",
        "\n",
        "print(\"y_predicted_values\", y_pred)\n",
        "print(\"Y_test_values\", Y_test)\n",
        "\n",
        "#import matplotlib.pyplot as plt \n",
        "cfm = confusion_matrix(Y_test, y_pred)\n",
        "\n",
        "print (cfm)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y_predicted_values [7 2 1 ... 4 5 6]\n",
            "Y_test_values [7 2 1 ... 4 5 6]\n",
            "[[ 973    0    4    0    0    1    1    1    0    0]\n",
            " [   0 1127    3    4    0    1    0    0    0    0]\n",
            " [   0    1 1027    2    0    0    0    1    1    0]\n",
            " [   0    0    5  997    0    6    0    1    1    0]\n",
            " [   1    1    3    0  967    0    4    0    3    3]\n",
            " [   1    0    1    4    0  884    1    1    0    0]\n",
            " [   5    2    1    1    1    8  940    0    0    0]\n",
            " [   0    2   17    3    0    1    0 1003    1    1]\n",
            " [   2    1    4    2    1    1    0    2  956    5]\n",
            " [   4    3    0    2    3    8    0    6    2  981]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rbNEij6Rpq11",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "c702ed64-c52d-4bd6-d10f-9b94c494dff1"
      },
      "cell_type": "code",
      "source": [
        "## A more elegant preserntation for a confusion matrix\n",
        "\n",
        "import itertools\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    #print(cm)\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "        \n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    #plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_confusion_matrix(cfm, classes=range(10), normalize=True,\n",
        "                      title='Confusion matrix for MNIST')"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normalized confusion matrix\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAFoCAYAAABAGRzjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4v8B9aK577yZbjEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f9ad9ad4f60>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "lx6Fzhrlyjuu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### DIscussion"
      ]
    },
    {
      "metadata": {
        "id": "IEge6xgB52bv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We use the test accuracy as the metrix to evaluate the performance of the model we build. \n",
        "\n",
        "**For batch norm layer** :\n",
        "\n",
        "We find that to increase the performance, the batch norm layer is better to add between conv layers or near the output layer, but before the dense layer.\n",
        "Through my experiment on adding different numbers of batch norm layer, I find my model with 2 batch norm layer will be better than my model with only one batch norm layer. And the first batch norm layer I add between the two conv layer, the second I add before the last dense layer near the output layer.\n",
        "\n",
        "Main parameters of my batch norm layer is: axis=-1, momentum=0.99, epsilon=0.001\n",
        "\n",
        "Sometimes batch norm layer will destroy the model, especially when we do batch norm before the first conv layer or in the output layer.\n",
        "\n",
        "For the reason, we can think that the batch norm will be some kind of adaptive (or learnable) pre-processing block with trainable parameters. Which also means that we need to back-propagate them.\n",
        "\n",
        "Here is the list of advantages of using Batch-Norm:\n",
        "\n",
        "1. Improves gradient flow, used on very deep models (Resnet need this)\n",
        "2. Allow higher learning rates\n",
        "3. Reduce dependency on initialization\n",
        "4. Gives some kind of regularization (Even make Dropout less important but keep using it)\n",
        "5. As a rule of thumb if you use Dropout+BatchNorm you don't need L2 regularization\n",
        "\n",
        "**For kernal size in conv layer**:  \n",
        "\n",
        "3X3 is enough for this classification experiment on MNIST dataset. 5X5 is so large that decreased the performance.\n",
        "The kernel size generally refers to the widthxheight of the filter mask. The max pooling layer, for example, returns the pixel with maximum value from a set of pixels within a mask (kernel). Very small kernal sizes will capture very fine details of the image. On the other hand having a bigger kernal size will leave out minute details in the image.\n",
        "\n",
        "**For dense layer**:\n",
        "\n",
        "128 is quite good, we have tried 5, 11, 64, 1000, we find slightly increase th dense  or make the dense really big, such as 1000, which won't make a big difference on the performance, but if the dense is so low, it decrease the performance severely.\n",
        "\n",
        "A dense layer we can understand it as a  regular layer of neurons in a neural network. Each neuron recieves input from all the neurons in the previous layer, thus densely connected. The layer has a weight matrix W, a bias vector b, and the activations of previous layer a. The following is te docstring of class Dense from the keras documentation:\n",
        "\n",
        "*output = activation(dot(input, kernel) + bias)*\n",
        "\n",
        "where activation is the element-wise activation function passed as the activation argument, kernel is a weights matrix created by the layer, and bias is a bias vector created by the layer.\n",
        "\n",
        "**For pooling layer**:\n",
        "\n",
        "2X2 is good for this experiment.\n",
        "Pooling layer It is also referred to as a downsampling layer. In this category, there are also several layer options, with maxpooling being the most popular. This basically takes a filter (normally of size 2x2) and a stride of the same length. It then applies it to the input volume and outputs the maximum number in every subregion that the filter convolves around.\n",
        "\n",
        "**For dropout layer**:\n",
        "I have two drop out layers in my model, both of them are after the conv and pooling layer, one dropout value is 0.25, another is 0.5, which are good choices.\n",
        "\n",
        "Dropout is a a technique used to tackle Overfitting . The Dropout method in keras.layers module takes in a float between 0 and 1, which is the fraction of the neurons to drop. Below is the docstring of the Dropout method from the documentation:\n",
        "\n",
        "Dropout consists in randomly setting a fraction rate of input units to 0 at each update during training time, which helps prevent overfitting.\n",
        "\n",
        "**For batch size**:\n",
        "\n",
        "My choice of 128 is a good guess. Both give us a not bad loss and a reasonalble tranning speed.\n",
        "\n",
        "batch size determines the number of samples in each mini batch. Its maximum is the number of all samples, which makes gradient descent accurate, the loss will decrease towards the minimum if the learning rate is small enough, but iterations are slower. Its minimum is 1, resulting in stochastic gradient descent: Fast but the direction of the gradient step is based only on one example, the loss may jump around.\n",
        "\n",
        "**For epoch**:\n",
        "\n",
        "My choice of 1 is not a good guess. I choose 1 only because of the trainning speed is so slow. \n",
        "\n",
        "The number of epochs is a hyperparameter that defines the number times that the learning algorithm will work through the entire training dataset.\n",
        "\n",
        "\n",
        "\n",
        "**All in all,** there is no way to determine a good network topology just from the number of inputs and outputs. It depends critically on the number of training examples and the complexity of the classification you are trying to learn. A scientist  Yoshua Bengio has proposed a very simple rule:\n",
        "\n",
        "Just keep adding layers until the test error does not improve anymore.\n",
        "\n",
        "This rule is in accordance with my results, I add one more conv layer and pooling layer, the permormance of my model increases."
      ]
    }
  ]
}